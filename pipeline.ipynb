{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# global variables\n",
    "OUTPUT_FOLDER = \"./output_images/\"\n",
    "TEST_FOLDER = \"./test_images/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('*.jpeg')\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "# Divide up into cars and notcars\n",
    "images = glob.glob('./non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images:\n",
    "        notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images:\n",
    "        cars.append(image)\n",
    "\n",
    "# Helper function to plot graphs and figures\n",
    "def plot_figures(figures, figSize, r = 1, c=1, fig_title=None, labels=None):\n",
    "    fig, axs = plt.subplots(ncols=c, nrows=r, figsize=figSize)\n",
    "    axs = axs.ravel()\n",
    "    for index, title in zip(range(len(figures)), figures):\n",
    "        axs[index].imshow(figures[title], plt.gray())\n",
    "        if(labels != None):\n",
    "            axs[index].set_title(labels[index])\n",
    "        axs[index].set_axis_off()\n",
    "    if labels is not None: plt.tight_layout()\n",
    "    if fig_title is not None:\n",
    "        fig.suptitle(fig_title, fontsize=16)\n",
    "\n",
    "# Define a function to return some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    test_img = mpimg.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = test_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = test_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "    \n",
    "data_info = data_look(cars, notcars)\n",
    "\n",
    "print('There are ', \n",
    "      data_info[\"n_cars\"], ' cars and', \n",
    "      data_info[\"n_notcars\"], ' non-cars')\n",
    "print('of size: ',data_info[\"image_shape\"], ' and data type:', \n",
    "      data_info[\"data_type\"])\n",
    "# Just for fun choose random car / not-car indices and plot example images   \n",
    "car_ind = np.random.randint(0, len(cars))\n",
    "notcar_ind = np.random.randint(0, len(notcars))\n",
    "    \n",
    "# Read in car / not-car images\n",
    "car_image = mpimg.imread(cars[car_ind])\n",
    "notcar_image = mpimg.imread(notcars[notcar_ind])\n",
    "\n",
    "# Display 48 randomly chosen car images from the dataset\n",
    "labels = []\n",
    "car_images = {}\n",
    "for i in range(0, 48):\n",
    "    idx = np.random.randint(0, len(cars))\n",
    "    car_images[i] = mpimg.imread(cars[idx])\n",
    "    labels.append(cars[idx])\n",
    "plot_figures(car_images, (6,8), 8, 6, \"Example Car Images\", None)\n",
    "plt.savefig(OUTPUT_FOLDER + \"car_visualization.png\")\n",
    "\n",
    "# Display 48 randomly chosen noncar images from the dataset\n",
    "labels = []\n",
    "notcar_images = {}\n",
    "for i in range(0, 48):\n",
    "    idx = np.random.randint(0, len(notcars))\n",
    "    notcar_images[i] = mpimg.imread(notcars[idx])\n",
    "    labels.append(notcars[idx])\n",
    "plot_figures(notcar_images, (6,8), 8, 6, \"Example Not-Car Images\", None)\n",
    "plt.savefig(OUTPUT_FOLDER + \"notcar_visualization.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "I noticed that the SVM does poorly on patches of images that are dimly lit (in shadows etc.), hence we use histogram equalization on the images before feature extraction. Here is a visualization of the results. We can see that histogram equalization is able to bring out the features in an image - the colors, edges, gradient and shape. Note that although traditionally histogram equalization is only to be used on grayscale image, here we treat each channel of a colorspace as a separate historgram to be equalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image must be a single channel image\n",
    "def equalize_hist(img):\n",
    "    if img.dtype == 'float32' or img.dtype == 'float64':\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    img = np.reshape(img, (img.shape[0], img.shape[1]))\n",
    "    return cv2.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# This will extract color_histograms and hog features\n",
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                     pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        feature_image = convert_color(image, cspace)\n",
    "\n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        \n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                feature_image_equalized = equalize_hist(feature_image[:,:,channel])\n",
    "                hog_features.append(get_hog_features(feature_image_equalized, \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)\n",
    "        else:\n",
    "            feature_image_equalized = equalize_hist(feature_image[:,:,hog_channel])\n",
    "            hog_features = get_hog_features(feature_image_equalized, orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "#         features.append(hog_features)\n",
    "\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    return cv2.resize(img, size).ravel()\n",
    "\n",
    "# Function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "from skimage.feature import hog\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "def convert_color(image, cspace='RGB'):\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HSV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'HLS':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        else:\n",
    "            feature_image = np.copy(image)\n",
    "    else:\n",
    "        feature_image = np.copy(image)\n",
    "    return feature_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize HOG\n",
    "Here we try out different color spaces and compare their visualizations to see which color spaces and which channels show the most contrast and therefore, are the best to use for feature extraction. It was noticed later on that a lot of false positives were showing up and those are patches of road / guardrail that were in the shadows. Hence, we can use this function to chery pick non-car images that the SVM is getting wrong and figure out why.\n",
    "\n",
    "Based on the plots below, it seems that S and V channel in the HSV colorspace provides the greatest contrast between car and non-car images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "spatial_size = (32,32)\n",
    "hist_bins = 32\n",
    "colorspace = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "images = glob.glob('./non-vehicles/*/image3689.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images[0:1]:\n",
    "        notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images[0:1]:\n",
    "        cars.append(image)\n",
    "\n",
    "cspaces = [\"RGB\", \"HSV\", \"LUV\", \"YCrCb\", \"HLS\", \"YUV\"]\n",
    "for car_filename, notcar_filename in zip(cars, notcars):\n",
    "    image = mpimg.imread(car_filename)\n",
    "    notcar_image = mpimg.imread(notcar_filename)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray = equalize_hist(gray)\n",
    "    notcar_gray = cv2.cvtColor(notcar_image, cv2.COLOR_RGB2GRAY)\n",
    "    notcar_gray = equalize_hist(notcar_gray)\n",
    "    fig, axes = plt.subplots(12,4, figsize=(8,24))\n",
    "    for row, cspace in enumerate(cspaces):\n",
    "        feature_image = convert_color(image, cspace)\n",
    "        notcar_feature_image = convert_color(notcar_image, cspace)\n",
    "        axes[2*row,0].imshow(gray, cmap='gray')\n",
    "        axes[2*row,0].set_title(\"Original car\")\n",
    "        axes[2*row+1,0].imshow(notcar_gray, cmap='gray')\n",
    "        axes[2*row+1,0].set_title(\"Original not car\")\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            feature_equalized = equalize_hist(feature_image[:,:,channel])\n",
    "            features, hog_image = get_hog_features(feature_equalized, \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=True, feature_vec=True)\n",
    "            axes[2*row,channel+1].imshow(hog_image, cmap='gray')\n",
    "            axes[2*row,channel+1].set_title(cspace + \"_car_hog_%d\" % channel)\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            notcar_feature_equalized = equalize_hist(notcar_feature_image[:,:,channel])\n",
    "            features, hog_image = get_hog_features(notcar_feature_equalized, \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=True, feature_vec=True)\n",
    "            axes[2*row+1,channel+1].imshow(hog_image, cmap='gray')\n",
    "            axes[2*row+1,channel+1].set_title(cspace + \"_noncar_hog_%d\" % channel)\n",
    "        fig.tight_layout()\n",
    "    fig.savefig(OUTPUT_FOLDER + \"hog_colorspace_comparision.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifer using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "\n",
    "# Divide up into cars and notcars\n",
    "images = glob.glob('./non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images:\n",
    "        notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images:\n",
    "        cars.append(image)\n",
    "\n",
    "# Reduce the sample size because HOG features are slow to compute\n",
    "sample_size = 8000\n",
    "cars = cars[0:sample_size]\n",
    "notcars = notcars[0:sample_size]\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "spatial_size = (32,32)\n",
    "hist_bins = 32\n",
    "colorspace = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "t=time.time()\n",
    "car_features = extract_features(cars, cspace=colorspace, spatial_size=(32,32),\n",
    "                        hist_bins=32, hist_range=(0,256), orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "notcar_features = extract_features(notcars, cspace=colorspace, spatial_size=(32,32),\n",
    "                        hist_bins=32, hist_range=(0,256), orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "\n",
    "print(\"Training with %d features on %d positive-datapoints and %d negative datapoints\" % (car_features[0].shape[0], sample_size, sample_size))\n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import grid_search\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "    \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Apply the scaler to X\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "t=time.time()\n",
    "\n",
    "# Grid search the best model\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10, 100]}\n",
    "svr = SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "svc = clf\n",
    "# Use a linear SVC \n",
    "# svc = LinearSVC()\n",
    "\n",
    "# Check the training time for the SVC\n",
    "# svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to find best parameters and train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Best Train Accuracy of SVC = ', round(svc.score(X_train, y_train), 4))\n",
    "print('Best Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "best_params = svc.best_params_\n",
    "print('Best parameters for SVC: ' + str(best_params))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, cspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    bboxes = []\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, cspace)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "#     hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "#     hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "#     hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "#     print(ch3.shape)\n",
    "#     print(hog3.shape)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "            \n",
    "            # Histogram equalization\n",
    "            window1 = equalize_hist(ch1[ytop:ytop+window, xleft:xleft+window])\n",
    "            window2 = equalize_hist(ch2[ytop:ytop+window, xleft:xleft+window])\n",
    "            window3 = equalize_hist(ch3[ytop:ytop+window, xleft:xleft+window])\n",
    "    \n",
    "            # Extract HOG for this patch\n",
    "#             hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "#             hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "#             hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "#             print(window1.shape, window2.shape, window3.shape)\n",
    "            hog_feat1 = get_hog_features(window1, orient, pix_per_cell, cell_per_block, feature_vec=True)\n",
    "            hog_feat2 = get_hog_features(window2, orient, pix_per_cell, cell_per_block, feature_vec=True)\n",
    "            hog_feat3 = get_hog_features(window3, orient, pix_per_cell, cell_per_block, feature_vec=True)\n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "#             print(hog_feat1.shape, hog_feat2.shape, hog_feat3.shape)\n",
    "            \n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "#             test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "            \n",
    "            test_features = X_scaler.transform(hog_features.reshape(1, -1))\n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                # print(svc.decision_function(test_features))\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                top_left = (xbox_left, ytop_draw+ystart)\n",
    "                bottom_right = (xbox_left+win_draw,ytop_draw+win_draw+ystart)\n",
    "                bboxes.append((top_left, bottom_right))\n",
    "                cv2.rectangle(draw_img, top_left, bottom_right,(0,0,255),6) \n",
    "                \n",
    "    return draw_img, bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1.5\n",
    "\n",
    "start = time.time()\n",
    "images = glob.glob(TEST_FOLDER + \"*.jpg\")\n",
    "for filename in images:\n",
    "    img = mpimg.imread(filename)\n",
    "    out_img, bboxes = find_cars(img, ystart, ystop, scale, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    plt.figure()\n",
    "    plt.imshow(out_img)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"sliding_windows_\" + filename.split(os.path.sep)[-1], out_img)\n",
    "end = time.time() - start\n",
    "print(\"%.2fs taken for %d images\" % (end, len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "1. Draw a heatmap based on list of detections\n",
    "2. Apply a threshold to remove false positives\n",
    "3. Draw bounding boxes on the final detected cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "images = glob.glob(TEST_FOLDER + \"*.jpg\")\n",
    "for filename in images:\n",
    "    img = mpimg.imread(filename)\n",
    "    out_img, bboxes = find_cars(img, ystart, ystop, scale, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, bboxes)\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,3)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"heatmap_\" + filename.split(os.path.sep)[-1], heatmap)\n",
    "    \n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    final_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    plt.figure()\n",
    "    plt.imshow(final_img)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"final_detected_cars_\" + filename.split(os.path.sep)[-1], final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
