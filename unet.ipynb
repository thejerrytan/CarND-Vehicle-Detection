{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "\n",
    "IMG_SIZE = (320,480,3) # Original image is 1920 x 1200 x 3, we downscale by 4 to make it manageable\n",
    "BBOX_SIZE = (64, 64)\n",
    "NUM_TO_SHOW = 10\n",
    "LABEL_MAP = {\n",
    "    \"car\": 1,\n",
    "    \"truck\": 2,\n",
    "    \"pedestrian\": 3,\n",
    "    \"trafficLight\": 4,\n",
    "    \"biker\": 5,\n",
    "    \"others\": 0 # background pixels\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"./object-dataset/labels.csv\", sep=\" \")\n",
    "fig, axes = plt.subplots(NUM_TO_SHOW, 3, figsize=(9, NUM_TO_SHOW * 9))\n",
    "# Visualize dataset\n",
    "for index, row in df.iterrows():\n",
    "    if index < NUM_TO_SHOW:\n",
    "        img = mpimg.imread(\"./object-dataset/\" + row[\"frame\"])\n",
    "        xmin = row[\"xmin\"]\n",
    "        xmax = row[\"xmax\"]\n",
    "        ymin = row[\"ymin\"]\n",
    "        ymax = row[\"ymax\"]\n",
    "        axes[index,0].imshow(img[ymin:ymax, xmin:xmax])\n",
    "        axes[index,0].set_title(row[\"label\"])\n",
    "        \n",
    "        axes[index,1].imshow(img)\n",
    "        axes[index,1].set_title(\"Original image\")\n",
    "        \n",
    "        # build up dataset\n",
    "        class_ = LABEL_MAP[row[\"label\"]]\n",
    "        label = np.zeros((img.shape[0], img.shape[1]))\n",
    "        label[ymin:ymax, xmin:xmax] = class_\n",
    "        axes[index,2].imshow(label*10, cmap='hot')\n",
    "        axes[index,2].set_title(\"Labelled image mask\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "FRACTION_TO_TEST = 0.8\n",
    "msk = np.random.rand(len(df)) < FRACTION_TO_TEST\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "print(\"Splitting into train and validation sets\")\n",
    "print(len(test))\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, df, batch_size=32, dim=(32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.df = df\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = len(df)\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.list_IDs)/ self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.list_IDs)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim, 1), dtype=int)\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            img = mpimg.imread(\"./object-dataset/\" + self.df.iloc[ID][\"frame\"])\n",
    "            # Store sample\n",
    "            X[i,] = cv2.resize(img, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "\n",
    "            # Store class\n",
    "            row = self.df.iloc[ID]\n",
    "            xmin = row[\"xmin\"]\n",
    "            xmax = row[\"xmax\"]\n",
    "            ymin = row[\"ymin\"]\n",
    "            ymax = row[\"ymax\"]\n",
    "            class_ = LABEL_MAP[row[\"label\"]]\n",
    "            label = np.zeros((img.shape[0], img.shape[1]))\n",
    "            label[ymin:ymax, xmin:xmax] = class_\n",
    "            label = cv2.resize(label, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "            y[i] = np.reshape(label, (label.shape[0], label.shape[1], 1))\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "class Unet(object):\n",
    "\n",
    "    def __init__(self, train, test, img_rows = 512, img_cols = 512):\n",
    "        self.training_generator = train\n",
    "        self.validation_generator = test\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "\n",
    "    def load_data(self):\n",
    "        pass\n",
    "\n",
    "    def get_unet(self):\n",
    "\n",
    "        inputs = Input((self.img_rows, self.img_cols, 3))\n",
    "\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print(\"conv1 shape:\",conv1.get_shape())\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        print(\"conv1 shape:\",conv1.get_shape())\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print(\"pool1 shape:\",pool1.get_shape())\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print(\"conv2 shape:\",conv2.get_shape())\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        print(\"conv2 shape:\",conv2.get_shape())\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print(\"pool2 shape:\",pool2.get_shape())\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print(\"conv3 shape:\",conv3.get_shape())\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        print(\"conv3 shape:\",conv3.get_shape())\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        print(\"pool3 shape:\",pool3.get_shape())\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        print(\"conv4 shape:\",conv4.get_shape())\n",
    "        drop4 = Dropout(0.5)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "        print(\"pool4 shape:\",pool4.get_shape())\n",
    "        print(\"drop4 shape:\",drop4.get_shape())\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        print(\"conv5 shape:\",conv5.get_shape())\n",
    "        drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "        print(\"up6 shape:\",up6.get_shape())\n",
    "        merge6 = concatenate([drop4,up6], axis = 3)\n",
    "        print(\"merge6 shape:\", merge6.get_shape())\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "        print(\"conv6 shape:\",conv6.get_shape())\n",
    "        \n",
    "        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        print(\"up7 shape:\", up7.get_shape())\n",
    "        merge7 = concatenate([conv3,up7], axis = 3)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "        merge8 = concatenate([conv2,up8], axis = 3)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = concatenate([conv1,up9], axis = 3)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "        model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "        model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # print(\"loading data\")\n",
    "        # imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        # print(\"loading data done\")\n",
    "        model = self.get_unet()\n",
    "        print(\"got unet\")\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "        print('Fitting model...')\n",
    "        model.fit_generator(generator=self.training_generator,\n",
    "                            validation_data=self.validation_generator,\n",
    "                            use_multiprocessing=True,\n",
    "                            workers=6, epochs=10, verbose=1, steps_per_epoch=steps_per_epoch,\n",
    "                            callbacks=[model_checkpoint])\n",
    "\n",
    "        self.model = model\n",
    "        \n",
    "\n",
    "    def save_img(self):\n",
    "\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load('imgs_mask_test.npy')\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"../results/%d.jpg\"%(i))\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (IMG_SIZE[0], IMG_SIZE[1]),\n",
    "          'batch_size': 32,\n",
    "          'n_classes': len(LABEL_MAP),\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "steps_per_epoch = int(len(train)//params['batch_size'])\n",
    "training_generator = DataGenerator(train, **params)\n",
    "validation_generator = DataGenerator(test, **params)\n",
    "model = Unet(training_generator, validation_generator, IMG_SIZE[0], IMG_SIZE[1])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
