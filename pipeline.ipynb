{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# global variables\n",
    "OUTPUT_FOLDER = \"./output_images/\"\n",
    "TEST_FOLDER = \"./test_images/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('*.jpeg')\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "# Divide up into cars and notcars\n",
    "images = glob.glob('./non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images:\n",
    "        notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images:\n",
    "        cars.append(image)\n",
    "\n",
    "# Helper function to plot graphs and figures\n",
    "def plot_figures(figures, figSize, r = 1, c=1, fig_title=None, labels=None):\n",
    "    fig, axs = plt.subplots(ncols=c, nrows=r, figsize=figSize)\n",
    "    axs = axs.ravel()\n",
    "    for index, title in zip(range(len(figures)), figures):\n",
    "        axs[index].imshow(figures[title], plt.gray())\n",
    "        if(labels != None):\n",
    "            axs[index].set_title(labels[index])\n",
    "        axs[index].set_axis_off()\n",
    "    if labels is not None: plt.tight_layout()\n",
    "    if fig_title is not None:\n",
    "        fig.suptitle(fig_title, fontsize=16)\n",
    "\n",
    "# Define a function to return some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    test_img = mpimg.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = test_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = test_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "    \n",
    "data_info = data_look(cars, notcars)\n",
    "\n",
    "print('There are ', \n",
    "      data_info[\"n_cars\"], ' cars and', \n",
    "      data_info[\"n_notcars\"], ' non-cars')\n",
    "print('of size: ',data_info[\"image_shape\"], ' and data type:', \n",
    "      data_info[\"data_type\"])\n",
    "# Just for fun choose random car / not-car indices and plot example images   \n",
    "car_ind = np.random.randint(0, len(cars))\n",
    "notcar_ind = np.random.randint(0, len(notcars))\n",
    "    \n",
    "# Read in car / not-car images\n",
    "car_image = mpimg.imread(cars[car_ind])\n",
    "notcar_image = mpimg.imread(notcars[notcar_ind])\n",
    "\n",
    "# Display 48 randomly chosen car images from the dataset\n",
    "labels = []\n",
    "car_images = {}\n",
    "for i in range(0, 48):\n",
    "    idx = np.random.randint(0, len(cars))\n",
    "    car_images[i] = mpimg.imread(cars[idx])\n",
    "    labels.append(cars[idx])\n",
    "plot_figures(car_images, (6,8), 8, 6, \"Example Car Images\", None)\n",
    "plt.savefig(OUTPUT_FOLDER + \"car_visualization.png\")\n",
    "\n",
    "# Display 48 randomly chosen noncar images from the dataset\n",
    "labels = []\n",
    "notcar_images = {}\n",
    "for i in range(0, 48):\n",
    "    idx = np.random.randint(0, len(notcars))\n",
    "    notcar_images[i] = mpimg.imread(notcars[idx])\n",
    "    labels.append(notcars[idx])\n",
    "plot_figures(notcar_images, (6,8), 8, 6, \"Example Not-Car Images\", None)\n",
    "plt.savefig(OUTPUT_FOLDER + \"notcar_visualization.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "False positives are coming from dimly light parts of the road, especially the guardrail. We have to augment the training set with images adjusted with a lower brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image is a RGB image\n",
    "# outputs a saturated RGB image that has been lowered in brightness by a random value\n",
    "def adjust_brightness(img, range=(40, 80)):\n",
    "    image = np.copy(img)\n",
    "    if (img.dtype == 'float32' or img.dtype == 'float64'):\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    v = np.random.randint(range[0], range[1])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    image[:,:,2] = cv2.add(image[:,:,2], -v)\n",
    "    \n",
    "    return (cv2.cvtColor(image, cv2.COLOR_HSV2RGB)).astype(np.float32) / 255\n",
    "\n",
    "images = glob.glob('./non-vehicles/*/image3689.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images[0:1]:\n",
    "    notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images[0:1]:\n",
    "    cars.append(image)\n",
    "\n",
    "NUM_AUGMENTATION = 5\n",
    "for car, notcar in zip(cars, notcars):\n",
    "    car_image = mpimg.imread(car)\n",
    "    notcar_image = mpimg.imread(notcar)\n",
    "    fig, axes = plt.subplots(2, NUM_AUGMENTATION +1, figsize=(2*NUM_AUGMENTATION, 2*2))\n",
    "    axes[0,0].imshow(car_image)\n",
    "    axes[0,0].set_title(\"Car Image\")\n",
    "    axes[1,0].imshow(notcar_image)\n",
    "    axes[1,0].set_title(\"Not Car Image\")\n",
    "    for i in range(1, NUM_AUGMENTATION+1):\n",
    "        augmented_car = adjust_brightness(car_image)\n",
    "        augmented_notcar = adjust_brightness(notcar_image)\n",
    "        axes[0, i].imshow(augmented_car)\n",
    "        axes[1, i].imshow(augmented_notcar)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(OUTPUT_FOLDER + \"augment_brightness_comparision.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "I noticed that the SVM does poorly on patches of images that are dimly lit (in shadows etc.), hence we use histogram equalization on the images before feature extraction. Here is a visualization of the results. We can see that histogram equalization is able to bring out the features in an image - the colors, edges, gradient and shape. Note that although traditionally histogram equalization is only to be used on grayscale image, here we treat each channel of a colorspace as a separate historgram to be equalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image must be a single channel image\n",
    "def equalize_hist(img):\n",
    "    if img.dtype == 'float32' or img.dtype == 'float64':\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    img = np.reshape(img, (img.shape[0], img.shape[1]))\n",
    "    return (cv2.equalizeHist(img)).astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# This will extract color_histograms and hog features\n",
    "def extract_features(imgs, hist_colorspace='RGB', cspace='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                     pix_per_cell=8, cell_per_block=2, hog_channel=0, augmentation_factor=5):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        for i in range(0, augmentation_factor):\n",
    "            if i != 0: image = adjust_brightness(image)\n",
    "#             image[:,:,0] = equalize_hist(image[:,:,0])\n",
    "#             image[:,:,1] = equalize_hist(image[:,:,1])\n",
    "#             image[:,:,2] = equalize_hist(image[:,:,2])\n",
    "            \n",
    "            # Apply bin_spatial() to get spatial color features\n",
    "            spatial_features = bin_spatial(image, size=spatial_size)\n",
    "            # Apply color_hist() also with a color space option\n",
    "            _, _, _, _, hist_features = color_hist(image, cspace=hist_colorspace, nbins=hist_bins, bins_range=hist_range)\n",
    "            \n",
    "            # apply color conversion for hog features\n",
    "            feature_image = convert_color(image, cspace)\n",
    "            \n",
    "            # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    feature_image_equalized = equalize_hist(feature_image[:,:,channel])\n",
    "                    # feature_image_equalized = feature_image[:,:,channel]\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                feature_image_equalized = equalize_hist(feature_image[:,:,hog_channel])\n",
    "                # feature_image_equalized = feature_image[:,:,hog_channel]\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "            # features.append(hog_features)\n",
    "\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32), feature_vec=True):\n",
    "    if feature_vec: return cv2.resize(img, size).ravel()\n",
    "    else: return cv2.resize(img, size)\n",
    "\n",
    "# Function to compute color histogram features  \n",
    "def color_hist(img, cspace='RGB', nbins=32, bins_range=(0, 256)):\n",
    "    img = convert_color(img, cspace)\n",
    "   # Compute the histogram of the RGB channels separately\n",
    "    rhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    ghist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    bhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    # Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return rhist, ghist, bhist, bin_centers, hist_features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "from skimage.feature import hog\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "# def convert_color(image, cspace='RGB'):\n",
    "#     if cspace != 'RGB':\n",
    "#         if cspace == 'HSV':\n",
    "#             feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "#         elif cspace == 'LUV':\n",
    "#             feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "#         elif cspace == 'HLS':\n",
    "#             feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "#         elif cspace == 'YUV':\n",
    "#             feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "#         else:\n",
    "#             feature_image = np.copy(image)\n",
    "#     else:\n",
    "#         feature_image = np.copy(image)\n",
    "#     if image.dtype == 'uint8': return (feature_image/255).astype(np.float32)\n",
    "#     else: return feature_image\n",
    "\n",
    "def convert_color(image, cspace='RGB'):\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HSV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'HLS':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(image)\n",
    "    return feature_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize spatial bins\n",
    "\n",
    "Here we compare spatial bins for car and non-car for different spatial sizes to determine the right spatial size to use.\n",
    "\n",
    "As can be seen from the graphs below, 16 x 16 resolution still retains enough visual enough to distinguish between a car and not-car, hence, in order to minimize length of feature vector, and increase real-time processing speed, we use 16x16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide up into cars and notcars\n",
    "images = glob.glob('./non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images[0:1]:\n",
    "    notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images[0:1]:\n",
    "    cars.append(image)\n",
    "        \n",
    "sizes = [(8,8), (16,16), (32,32)]\n",
    "for car, notcar in zip(cars, notcars):\n",
    "    image = mpimg.imread(car)\n",
    "    notcar_image = mpimg.imread(notcar)\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(8,4))\n",
    "    axes[0,0].imshow(image)\n",
    "    axes[0,0].set_title(\"Car\")\n",
    "    axes[1,0].imshow(notcar_image)\n",
    "    axes[1,0].set_title(\"Not Car\")\n",
    "    for col, size in enumerate(sizes):\n",
    "        car_bins = bin_spatial(image, size=size, feature_vec=False)\n",
    "        notcar_bins = bin_spatial(notcar_image, size=size, feature_vec=False)\n",
    "        axes[0, col+1].imshow(car_bins)\n",
    "        axes[0, col+1].set_title(\"%d x %d\" % (size[0], size[1]))\n",
    "        axes[1, col+1].imshow(notcar_bins)\n",
    "        axes[1, col+1].set_title(\"%d x %d\" % (size[0], size[1]))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(OUTPUT_FOLDER +  \"spatial_bining_comparision.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize histogram\n",
    "Here we try out different color spaces and compare their histograms to see which color spaces and which channels show the most contrast.\n",
    "\n",
    "Upon inspection, RGB, YUV and YCrCb appear to be good candidates. I decided to choose RGB for color_hist feature because matplotlib reads images in RGB by default, thus saving us an extra colour conversion step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('./non-vehicles/*/image3689.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images[0:1]:\n",
    "        notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images[0:1]:\n",
    "        cars.append(image)\n",
    "\n",
    "cspaces = [\"RGB\", \"HSV\", \"LUV\", \"YCrCb\", \"HLS\", \"YUV\"]\n",
    "nbins = 32\n",
    "for car_filename, notcar_filename in zip(cars, notcars):\n",
    "    image = mpimg.imread(car_filename)\n",
    "    notcar_image = mpimg.imread(notcar_filename)\n",
    "    fig, axes = plt.subplots(12,4, figsize=(12,32))\n",
    "    for row, cspace in enumerate(cspaces):\n",
    "        feature_image = convert_color(image, cspace)\n",
    "        notcar_feature_image = convert_color(notcar_image, cspace)\n",
    "        feature_image = (feature_image * 255).astype(np.uint8)\n",
    "        notcar_feature_image = (notcar_feature_image * 255).astype(np.uint8)\n",
    "        axes[2*row,0].imshow(image)\n",
    "        axes[2*row,0].set_title(\"Original car\")\n",
    "        axes[2*row+1,0].imshow(notcar_image)\n",
    "        axes[2*row+1,0].set_title(\"Original not car\")\n",
    "        crh, cgh, cbh, cbincen, car_hist = color_hist(feature_image, nbins=nbins, bins_range=(0,256))\n",
    "        rh, gh, bh, bincen, notcar_hist = color_hist(notcar_feature_image, nbins=nbins, bins_range=(0,256))\n",
    "        axes[2*row, 1].bar(cbincen, crh[0])\n",
    "        axes[2*row, 1].set_xlim(0, 256)\n",
    "        axes[2*row, 1].set_title(cspace[0])\n",
    "        axes[2*row, 2].bar(cbincen, cgh[0])\n",
    "        axes[2*row, 2].set_xlim(0, 256)\n",
    "        axes[2*row, 2].set_title(cspace[1])\n",
    "        axes[2*row, 3].bar(cbincen, cbh[0])\n",
    "        axes[2*row, 3].set_xlim(0, 256)\n",
    "        axes[2*row, 3].set_title(cspace[2])\n",
    "        axes[2*row+1, 1].bar(bincen, rh[0])\n",
    "        axes[2*row+1, 1].set_xlim(0, 256)\n",
    "        axes[2*row+1, 1].set_title(cspace[0])\n",
    "        axes[2*row+1, 2].bar(bincen, gh[0])\n",
    "        axes[2*row+1, 2].set_xlim(0, 256)\n",
    "        axes[2*row+1, 2].set_title(cspace[1])\n",
    "        axes[2*row+1, 3].bar(bincen, bh[0])\n",
    "        axes[2*row+1, 3].set_xlim(0, 256)\n",
    "        axes[2*row+1, 3].set_title(cspace[2])\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(OUTPUT_FOLDER + \"color_histogram_comparision.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize HOG\n",
    "Here we try out different color spaces and compare their visualizations to see which color spaces and which channels show the most contrast and therefore, are the best to use for feature extraction. It was noticed later on that a lot of false positives were showing up and those are patches of road / guardrail that were in the shadows. Hence, we can use this function to chery pick non-car images that the SVM is getting wrong and figure out why.\n",
    "\n",
    "Based on the plots below, it seems that S and V channel in the HSV colorspace provides the greatest contrast between car and non-car images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "colorspace = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 16\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "images = glob.glob('./non-vehicles/*/image3689.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images[0:1]:\n",
    "        notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images[0:1]:\n",
    "        cars.append(image)\n",
    "\n",
    "cspaces = [\"RGB\", \"HSV\", \"LUV\", \"YCrCb\", \"HLS\", \"YUV\"]\n",
    "for car_filename, notcar_filename in zip(cars, notcars):\n",
    "    image = mpimg.imread(car_filename)\n",
    "    notcar_image = mpimg.imread(notcar_filename)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     gray = equalize_hist(gray)\n",
    "    notcar_gray = cv2.cvtColor(notcar_image, cv2.COLOR_RGB2GRAY)\n",
    "#     notcar_gray = equalize_hist(notcar_gray)\n",
    "    fig, axes = plt.subplots(12,4, figsize=(8,24))\n",
    "    for row, cspace in enumerate(cspaces):\n",
    "        feature_image = convert_color(image, cspace)\n",
    "        notcar_feature_image = convert_color(notcar_image, cspace)\n",
    "        axes[2*row,0].imshow(gray, cmap='gray')\n",
    "        axes[2*row,0].set_title(\"Original car\")\n",
    "        axes[2*row+1,0].imshow(notcar_gray, cmap='gray')\n",
    "        axes[2*row+1,0].set_title(\"Original not car\")\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "#             feature_equalized = equalize_hist(feature_image[:,:,channel])\n",
    "            features, hog_image = get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=True, feature_vec=True)\n",
    "            axes[2*row,channel+1].imshow(hog_image, cmap='gray')\n",
    "            axes[2*row,channel+1].set_title(cspace + \"_car_hog_%d\" % channel)\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "#             notcar_feature_equalized = equalize_hist(notcar_feature_image[:,:,channel])\n",
    "            features, hog_image = get_hog_features(notcar_feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=True, feature_vec=True)\n",
    "            axes[2*row+1,channel+1].imshow(hog_image, cmap='gray')\n",
    "            axes[2*row+1,channel+1].set_title(cspace + \"_noncar_hog_%d\" % channel)\n",
    "        fig.tight_layout()\n",
    "    fig.savefig(OUTPUT_FOLDER + \"hog_colorspace_comparision.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifer using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "\n",
    "# Divide up into cars and notcars\n",
    "images = glob.glob('./non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images:\n",
    "        notcars.append(image)\n",
    "images = glob.glob('./vehicles/*/*.png')\n",
    "for image in images:\n",
    "        cars.append(image)\n",
    "\n",
    "# Reduce the sample size because HOG features are slow to compute\n",
    "sample_size = 5000\n",
    "cars = cars[0:sample_size]\n",
    "notcars = notcars[0:sample_size]\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "augmentation_factor = 1 # extra images to add per training data such that final dataset size = augmentation_factor * sample_size\n",
    "spatial_size = (16,16)\n",
    "hist_bins = 32\n",
    "colorspace = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb, to be used for HOG\n",
    "hist_colorspace = 'RGB' # colorspace to be used for histogram of colors\n",
    "orient = 9\n",
    "pix_per_cell = 16\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "t=time.time()\n",
    "car_features = extract_features(cars, hist_colorspace=hist_colorspace, cspace=colorspace, spatial_size=spatial_size,\n",
    "                        hist_bins=32, hist_range=(0,256), orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, augmentation_factor=augmentation_factor)\n",
    "notcar_features = extract_features(notcars, hist_colorspace=hist_colorspace, cspace=colorspace, spatial_size=spatial_size,\n",
    "                        hist_bins=32, hist_range=(0,256), orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, augmentation_factor=augmentation_factor)\n",
    "\n",
    "print(\"Training with %d features on %d positive-datapoints and %d negative datapoints\" % (car_features[0].shape[0], len(car_features), len(notcar_features)))\n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import grid_search\n",
    "import pickle\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "    \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Apply the scaler to X\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "t=time.time()\n",
    "\n",
    "# Grid search the best model\n",
    "parameters = {'kernel':('linear',), 'C':[0.1]}\n",
    "svr = SVC()\n",
    "svc = grid_search.GridSearchCV(svr, parameters)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Check the training time for the SVC\n",
    "# svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to find best parameters and train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Best Train Accuracy of SVC = ', round(svc.score(X_train, y_train), 4))\n",
    "print('Best Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "best_params = svc.best_params_\n",
    "print('Best parameters for SVC: ' + str(best_params))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "\n",
    "# Save the model\n",
    "with open(\"svc_trained_%d_samples\" % sample_size, 'wb') as f:\n",
    "    pickle.dump(svc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, hist_cspace, cspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    bboxes = []\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, cspace)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "    \n",
    "    # Equalize histogram - although equalizing per window would give the best results, that would be too slow\n",
    "    # Hence we only equalize the entire patch of the image that is bounded by the road.\n",
    "#     ch1 = equalize_hist(ch1)\n",
    "#     ch2 = equalize_hist(ch2)\n",
    "#     ch3 = equalize_hist(ch3)\n",
    "#     ctrans_tosearch_equalized = cv2.merge((ch1, ch2, ch3))\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "            \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            _, _, _, _, hist_features = color_hist(subimg, cspace=hist_cspace, nbins=hist_bins)\n",
    "            \n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                # print(svc.decision_function(test_features))\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                top_left = (xbox_left, ytop_draw+ystart)\n",
    "                bottom_right = (xbox_left+win_draw,ytop_draw+win_draw+ystart)\n",
    "                bboxes.append((top_left, bottom_right))\n",
    "                cv2.rectangle(draw_img, top_left, bottom_right,(0,0,255),6) \n",
    "                \n",
    "    return draw_img, bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "small_scale = 1.2\n",
    "small_ystart = 380\n",
    "small_ystop = 520\n",
    "\n",
    "med_scale = 1.5\n",
    "med_ystart = 380\n",
    "med_ystop = 680\n",
    "\n",
    "large_scale = 1.6\n",
    "large_ystart = 400\n",
    "large_ystop = 680\n",
    "\n",
    "pix_per_cell = 16\n",
    "\n",
    "start = time.time()\n",
    "images = glob.glob(TEST_FOLDER + \"*.jpg\")\n",
    "fig, axes = plt.subplots(len(images), 3, figsize=(4*3, 4*len(images)))\n",
    "for row, filename in enumerate(images):\n",
    "    img = mpimg.imread(filename)\n",
    "    out1_img, small_bboxes = find_cars(img, small_ystart, small_ystop, small_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    out2_img, medium_bboxes = find_cars(img, med_ystart, med_ystop, med_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    out3_img, large_bboxes = find_cars(img, large_ystart, large_ystop, large_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    axes[row, 0].imshow(out1_img)\n",
    "    axes[row, 0].set_title(\"small_scale 1.2\")\n",
    "    axes[row, 1].imshow(out2_img)\n",
    "    axes[row, 1].set_title(\"med_scale 1.5\")\n",
    "    axes[row, 2].imshow(out3_img)\n",
    "    axes[row, 2].set_title(\"large_scale 1.6\")\n",
    "    plt.imsave(OUTPUT_FOLDER + \"sliding_small_windows_\" + filename.split(os.path.sep)[-1], out1_img)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"sliding_medium_windows_\" + filename.split(os.path.sep)[-1], out2_img)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"sliding_large_windows_\" + filename.split(os.path.sep)[-1], out3_img)\n",
    "end = time.time() - start\n",
    "fig.savefig(OUTPUT_FOLDER + \"sliding_windows_comparison\")\n",
    "print(\"%.2fs taken for %d images\" % (end, len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "1. Draw a heatmap based on list of detections\n",
    "2. Apply a threshold to remove false positives\n",
    "3. Draw bounding boxes on the final detected cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def draw_bboxes(img, bboxes):\n",
    "    for top_left, bottom_right in bboxes:\n",
    "        cv2.rectangle(img, top_left, bottom_right,(0,0,255),6) \n",
    "    return img\n",
    "\n",
    "images = glob.glob(TEST_FOLDER + \"*.jpg\")\n",
    "bboxes = []\n",
    "for filename in images:\n",
    "    img = mpimg.imread(filename)\n",
    "    out1_img, small_bboxes = find_cars(img, small_ystart, small_ystop, small_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    out2_img, medium_bboxes = find_cars(img, med_ystart, med_ystop, med_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    out3_img, large_bboxes = find_cars(img, large_ystart, large_ystop, large_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "    # combine all bounding boxes\n",
    "    bboxes = small_bboxes + medium_bboxes + large_bboxes\n",
    "    out4_img = draw_bboxes(img, bboxes)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"sliding_windows_combined_\" + filename.split(os.path.sep)[-1], out4_img)\n",
    "    \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, bboxes)\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat, 2)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"heatmap_\" + filename.split(os.path.sep)[-1], heatmap)\n",
    "    \n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    final_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    plt.figure()\n",
    "    plt.imshow(final_img)\n",
    "    plt.imsave(OUTPUT_FOLDER + \"final_detected_cars_\" + filename.split(os.path.sep)[-1], final_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together, run a video through the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img):\n",
    "    _, small_bboxes = find_cars(img, small_ystart, small_ystop, small_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    _, medium_bboxes = find_cars(img, med_ystart, med_ystop, med_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    _, large_bboxes = find_cars(img, large_ystart, large_ystop, large_scale, hist_colorspace, colorspace, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    \n",
    "    bboxes = small_bboxes + medium_bboxes + large_bboxes\n",
    "    \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, bboxes)\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat, 4)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    labels = label(heatmap)\n",
    "    final_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_file = 'test_video_out.mp4'\n",
    "clip_test = VideoFileClip('test_video.mp4')\n",
    "clip_test_out = clip_test.fl_image(process_frame)\n",
    "%time clip_test_out.write_videofile(test_out_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_out_file = 'project_video_out.mp4'\n",
    "clip_test = VideoFileClip('project_video.mp4')\n",
    "clip_test_out = clip_test.fl_image(process_frame)\n",
    "%time clip_test_out.write_videofile(project_out_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
