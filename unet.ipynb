{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jerry/miniconda2/envs/CarND-Term1-Upgrade/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/Jerry/miniconda2/envs/CarND-Term1-Upgrade/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "\n",
    "IMG_SIZE = (320,480,3) # Original image is 1920 x 1200 x 3, we downscale by 4 to make it manageable\n",
    "BBOX_SIZE = (64, 64)\n",
    "NUM_TO_SHOW = 10\n",
    "LABEL_MAP = {\n",
    "    \"car\": 1,\n",
    "    \"truck\": 2,\n",
    "    \"pedestrian\": 3,\n",
    "    \"trafficLight\": 4,\n",
    "    \"biker\": 5,\n",
    "    \"others\": 0 # background pixels\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"./object-dataset/labels.csv\", sep=\" \")\n",
    "df = df[df[\"label\"] == \"car\"]\n",
    "fig, axes = plt.subplots(NUM_TO_SHOW, 3, figsize=(9, NUM_TO_SHOW * 3))\n",
    "# Visualize dataset\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if count < NUM_TO_SHOW and row[\"label\"] == \"car\":\n",
    "        img = mpimg.imread(\"./object-dataset/\" + row[\"frame\"])\n",
    "        xmin = row[\"xmin\"]\n",
    "        xmax = row[\"xmax\"]\n",
    "        ymin = row[\"ymin\"]\n",
    "        ymax = row[\"ymax\"]\n",
    "        axes[count,0].imshow(img[ymin:ymax, xmin:xmax])\n",
    "        axes[count,0].set_title(row[\"label\"] + \" \" + str(img[ymin:ymax, xmin:xmax].shape))\n",
    "        \n",
    "        axes[count,1].imshow(img)\n",
    "        axes[count,1].set_title(\"Original image\")\n",
    "        \n",
    "        # build up dataset\n",
    "        class_ = LABEL_MAP[row[\"label\"]]\n",
    "        label = np.zeros((img.shape[0], img.shape[1]))\n",
    "        label[ymin:ymax, xmin:xmax] = class_\n",
    "        axes[count,2].imshow(label*10, cmap='hot')\n",
    "        axes[count,2].set_title(\"Labelled image mask\")\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into train and validation sets\n",
      "(12087, 8)\n",
      "(48701, 8)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "FRACTION_TO_TEST = 0.8\n",
    "msk = np.random.rand(len(df)) < FRACTION_TO_TEST\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "print(\"Splitting into train and validation sets\")\n",
    "print(test.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, df, batch_size=32, dim=(32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True, sample_weight = None):\n",
    "        'Initialization'\n",
    "        self.df = df\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = len(df)\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_weight = sample_weight\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.list_IDs)/ self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y, W = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y, W\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.list_IDs)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, self.dim[0] * self.dim[1], self.n_classes), dtype=int)\n",
    "        W = np.empty((self.batch_size, self.dim[0] * self.dim[1]))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            img = mpimg.imread(\"./object-dataset/\" + self.df.iloc[ID][\"frame\"])\n",
    "            # Store sample\n",
    "            X[i,] = cv2.resize(img, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "\n",
    "            # Store class\n",
    "            row = self.df.iloc[ID]\n",
    "            xmin = row[\"xmin\"]\n",
    "            xmax = row[\"xmax\"]\n",
    "            ymin = row[\"ymin\"]\n",
    "            ymax = row[\"ymax\"]\n",
    "            # Do a one-hot encoding depthwise -> if pixel(x,y) is a vehicle [x,y,0] = 0 and [x,y,1] = 1\n",
    "            label = np.zeros((img.shape[0], img.shape[1]))\n",
    "            label[ymin:ymax, xmin:xmax] = 1 # vehicle layer\n",
    "            # mask = np.where(label[:,:,1] != 1)\n",
    "            # mask = tuple([mask[0], mask[1], np.zeros_like(mask[0])])\n",
    "            # label[mask] = 1 # background layer\n",
    "            label = cv2.resize(label, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "            # y[i] = np.reshape(label, (label.shape[0], label.shape[1], 1))\n",
    "            y[i] = np.reshape(np.ravel(label), (label.shape[0] * label.shape[1], 1))\n",
    "            # y[i] = np.reshape(np.ravel(label), (label.shape[0]*label.shape[1],self.n_classes))\n",
    "            \n",
    "            # Sample weight\n",
    "            sample_weight = np.zeros_like(label)\n",
    "            sample_weight[np.where(label == 1)] = 1\n",
    "            sample_weight[np.where(label == 0)] = 0.001\n",
    "            W[i] = np.ravel(sample_weight)\n",
    "\n",
    "        return X, y, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[249., 255., 255.],\n",
       "          [247., 255., 253.],\n",
       "          [248., 255., 254.],\n",
       "          ...,\n",
       "          [ 25.,  28.,  25.],\n",
       "          [ 72.,  77.,  63.],\n",
       "          [185., 183., 161.]],\n",
       " \n",
       "         [[254., 255., 255.],\n",
       "          [254., 255., 255.],\n",
       "          [254., 255., 255.],\n",
       "          ...,\n",
       "          [ 42.,  43.,  32.],\n",
       "          [107., 109.,  89.],\n",
       "          [153., 152., 128.]],\n",
       " \n",
       "         [[255., 254., 255.],\n",
       "          [255., 254., 255.],\n",
       "          [255., 254., 255.],\n",
       "          ...,\n",
       "          [ 55.,  52.,  38.],\n",
       "          [ 88.,  86.,  65.],\n",
       "          [ 86.,  85.,  66.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 35.,  37.,  36.],\n",
       "          [ 35.,  37.,  36.],\n",
       "          [ 35.,  37.,  36.],\n",
       "          ...,\n",
       "          [110., 111., 105.],\n",
       "          [112., 113., 107.],\n",
       "          [112., 113., 107.]],\n",
       " \n",
       "         [[ 36.,  38.,  37.],\n",
       "          [ 34.,  36.,  35.],\n",
       "          [ 37.,  39.,  38.],\n",
       "          ...,\n",
       "          [113., 114., 108.],\n",
       "          [113., 114., 108.],\n",
       "          [112., 113., 107.]],\n",
       " \n",
       "         [[ 36.,  38.,  37.],\n",
       "          [ 34.,  36.,  35.],\n",
       "          [ 37.,  39.,  38.],\n",
       "          ...,\n",
       "          [112., 113., 107.],\n",
       "          [113., 114., 108.],\n",
       "          [114., 115., 109.]]],\n",
       " \n",
       " \n",
       "        [[[126., 112., 108.],\n",
       "          [127., 127., 139.],\n",
       "          [178., 184., 209.],\n",
       "          ...,\n",
       "          [225., 229., 238.],\n",
       "          [225., 229., 238.],\n",
       "          [225., 229., 238.]],\n",
       " \n",
       "         [[ 53.,  52.,  51.],\n",
       "          [ 77.,  79.,  90.],\n",
       "          [175., 177., 192.],\n",
       "          ...,\n",
       "          [225., 229., 238.],\n",
       "          [224., 228., 237.],\n",
       "          [224., 228., 237.]],\n",
       " \n",
       "         [[ 78.,  86.,  81.],\n",
       "          [ 68.,  70.,  77.],\n",
       "          [132., 131., 134.],\n",
       "          ...,\n",
       "          [222., 226., 235.],\n",
       "          [222., 226., 235.],\n",
       "          [224., 228., 236.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 22.,  22.,  22.],\n",
       "          [ 22.,  22.,  22.],\n",
       "          [ 20.,  20.,  20.],\n",
       "          ...,\n",
       "          [ 74.,  73.,  68.],\n",
       "          [ 61.,  60.,  55.],\n",
       "          [ 66.,  65.,  60.]],\n",
       " \n",
       "         [[ 21.,  21.,  21.],\n",
       "          [ 21.,  21.,  21.],\n",
       "          [ 21.,  21.,  21.],\n",
       "          ...,\n",
       "          [ 67.,  66.,  61.],\n",
       "          [ 66.,  64.,  60.],\n",
       "          [ 61.,  60.,  55.]],\n",
       " \n",
       "         [[ 21.,  21.,  21.],\n",
       "          [ 21.,  21.,  21.],\n",
       "          [ 21.,  21.,  21.],\n",
       "          ...,\n",
       "          [ 63.,  62.,  57.],\n",
       "          [ 70.,  69.,  64.],\n",
       "          [ 63.,  62.,  57.]]],\n",
       " \n",
       " \n",
       "        [[[148., 141., 141.],\n",
       "          [125., 119., 132.],\n",
       "          [128., 117., 140.],\n",
       "          ...,\n",
       "          [ 25.,  18.,  12.],\n",
       "          [ 23.,  18.,  14.],\n",
       "          [ 22.,  19.,  14.]],\n",
       " \n",
       "         [[127., 129., 139.],\n",
       "          [126., 134., 141.],\n",
       "          [127., 137., 146.],\n",
       "          ...,\n",
       "          [ 22.,  19.,  14.],\n",
       "          [ 22.,  18.,  14.],\n",
       "          [ 24.,  19.,  13.]],\n",
       " \n",
       "         [[128., 132., 146.],\n",
       "          [130., 134., 143.],\n",
       "          [131., 135., 142.],\n",
       "          ...,\n",
       "          [ 20.,  19.,  14.],\n",
       "          [ 26.,  20.,  13.],\n",
       "          [ 37.,  27.,  14.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 27.,  22.,  18.],\n",
       "          [ 27.,  22.,  18.],\n",
       "          [ 26.,  21.,  18.],\n",
       "          ...,\n",
       "          [ 53.,  36.,  25.],\n",
       "          [ 55.,  38.,  25.],\n",
       "          [ 56.,  38.,  26.]],\n",
       " \n",
       "         [[ 27.,  22.,  18.],\n",
       "          [ 26.,  21.,  17.],\n",
       "          [ 26.,  21.,  18.],\n",
       "          ...,\n",
       "          [ 47.,  32.,  23.],\n",
       "          [ 52.,  36.,  26.],\n",
       "          [ 54.,  37.,  27.]],\n",
       " \n",
       "         [[ 27.,  22.,  18.],\n",
       "          [ 26.,  21.,  17.],\n",
       "          [ 26.,  21.,  18.],\n",
       "          ...,\n",
       "          [ 45.,  31.,  22.],\n",
       "          [ 48.,  34.,  25.],\n",
       "          [ 52.,  36.,  28.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[248., 255., 254.],\n",
       "          [245., 254., 251.],\n",
       "          [246., 255., 252.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[253., 255., 254.],\n",
       "          [254., 255., 255.],\n",
       "          [254., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 254., 255.],\n",
       "          [255., 254., 255.],\n",
       "          [255., 254., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 35.,  35.,  35.],\n",
       "          [ 36.,  36.,  36.],\n",
       "          [ 38.,  38.,  38.],\n",
       "          ...,\n",
       "          [ 76.,  78.,  78.],\n",
       "          [ 75.,  77.,  76.],\n",
       "          [ 76.,  78.,  78.]],\n",
       " \n",
       "         [[ 29.,  29.,  31.],\n",
       "          [ 30.,  30.,  32.],\n",
       "          [ 34.,  34.,  35.],\n",
       "          ...,\n",
       "          [ 78.,  80.,  79.],\n",
       "          [ 76.,  78.,  77.],\n",
       "          [ 80.,  82.,  81.]],\n",
       " \n",
       "         [[ 25.,  24.,  28.],\n",
       "          [ 26.,  26.,  30.],\n",
       "          [ 28.,  28.,  32.],\n",
       "          ...,\n",
       "          [ 79.,  81.,  80.],\n",
       "          [ 76.,  78.,  77.],\n",
       "          [ 70.,  72.,  71.]]],\n",
       " \n",
       " \n",
       "        [[[135., 130., 136.],\n",
       "          [119., 115., 122.],\n",
       "          [123., 113., 127.],\n",
       "          ...,\n",
       "          [183., 181., 184.],\n",
       "          [182., 180., 183.],\n",
       "          [180., 178., 181.]],\n",
       " \n",
       "         [[132., 127., 135.],\n",
       "          [127., 128., 135.],\n",
       "          [124., 130., 136.],\n",
       "          ...,\n",
       "          [184., 183., 181.],\n",
       "          [182., 182., 180.],\n",
       "          [184., 183., 181.]],\n",
       " \n",
       "         [[120., 130., 134.],\n",
       "          [123., 132., 137.],\n",
       "          [126., 133., 136.],\n",
       "          ...,\n",
       "          [185., 184., 182.],\n",
       "          [183., 182., 180.],\n",
       "          [183., 182., 180.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 20.,  19.,  17.],\n",
       "          [ 20.,  19.,  17.],\n",
       "          [ 20.,  19.,  17.],\n",
       "          ...,\n",
       "          [ 23.,  17.,  17.],\n",
       "          [ 23.,  17.,  17.],\n",
       "          [ 23.,  17.,  17.]],\n",
       " \n",
       "         [[ 20.,  19.,  17.],\n",
       "          [ 20.,  19.,  17.],\n",
       "          [ 20.,  19.,  17.],\n",
       "          ...,\n",
       "          [ 23.,  17.,  17.],\n",
       "          [ 23.,  17.,  17.],\n",
       "          [ 23.,  17.,  17.]],\n",
       " \n",
       "         [[ 20.,  19.,  17.],\n",
       "          [ 20.,  19.,  17.],\n",
       "          [ 20.,  19.,  17.],\n",
       "          ...,\n",
       "          [ 23.,  17.,  17.],\n",
       "          [ 23.,  17.,  17.],\n",
       "          [ 23.,  17.,  17.]]],\n",
       " \n",
       " \n",
       "        [[[ 79.,  46.,  28.],\n",
       "          [ 54.,  23.,  11.],\n",
       "          [ 46.,  18.,  12.],\n",
       "          ...,\n",
       "          [ 44.,  31.,  25.],\n",
       "          [ 45.,  30.,  23.],\n",
       "          [ 49.,  35.,  26.]],\n",
       " \n",
       "         [[ 24.,  20.,  24.],\n",
       "          [ 21.,  18.,  21.],\n",
       "          [ 31.,  31.,  31.],\n",
       "          ...,\n",
       "          [ 41.,  22.,  23.],\n",
       "          [ 44.,  28.,  23.],\n",
       "          [ 51.,  36.,  29.]],\n",
       " \n",
       "         [[ 24.,  20.,  20.],\n",
       "          [ 24.,  21.,  17.],\n",
       "          [ 30.,  26.,  17.],\n",
       "          ...,\n",
       "          [ 62.,  38.,  38.],\n",
       "          [ 51.,  31.,  30.],\n",
       "          [ 55.,  37.,  35.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 33.,  33.,  33.],\n",
       "          [ 33.,  33.,  33.],\n",
       "          [ 33.,  33.,  33.],\n",
       "          ...,\n",
       "          [ 81.,  78.,  71.],\n",
       "          [ 84.,  81.,  74.],\n",
       "          [ 84.,  81.,  74.]],\n",
       " \n",
       "         [[ 32.,  32.,  32.],\n",
       "          [ 32.,  32.,  32.],\n",
       "          [ 32.,  32.,  32.],\n",
       "          ...,\n",
       "          [ 87.,  84.,  77.],\n",
       "          [ 87.,  84.,  77.],\n",
       "          [ 83.,  80.,  73.]],\n",
       " \n",
       "         [[ 32.,  32.,  32.],\n",
       "          [ 32.,  32.,  32.],\n",
       "          [ 32.,  32.,  32.],\n",
       "          ...,\n",
       "          [ 85.,  82.,  75.],\n",
       "          [ 83.,  80.,  73.],\n",
       "          [ 86.,  83.,  76.]]]]), array([[[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         ...,\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]],\n",
       " \n",
       "        [[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         ...,\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]],\n",
       " \n",
       "        [[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         ...,\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         ...,\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]],\n",
       " \n",
       "        [[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         ...,\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]],\n",
       " \n",
       "        [[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         ...,\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]]), array([[0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        ...,\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample weights\n",
    "weights = np.zeros((IMG_SIZE[0] * IMG_SIZE[1], 2))\n",
    "weights[:,0] += 0.001\n",
    "weights[:,1] += 1\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (IMG_SIZE[0], IMG_SIZE[1]),\n",
    "          'batch_size': 8,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'sample_weight': weights}\n",
    "\n",
    "validation_generator = DataGenerator(test, **params)\n",
    "validation_generator.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  (?, 320, 480, 2)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 320, 480, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 320, 480, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 320, 480, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 160, 240, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 160, 240, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 160, 240, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 80, 120, 128) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 80, 120, 256) 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 80, 120, 256) 590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 40, 60, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 40, 60, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 40, 60, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 60, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 20, 30, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 20, 30, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 20, 30, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 30, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 40, 60, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 40, 60, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 40, 60, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 40, 60, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 40, 60, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 80, 120, 512) 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 80, 120, 256) 524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 80, 120, 512) 0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 80, 120, 256) 1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 80, 120, 256) 590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 160, 240, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 160, 240, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 160, 240, 256 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 160, 240, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 160, 240, 128 147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 320, 480, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 320, 480, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 320, 480, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 320, 480, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 320, 480, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 320, 480, 2)  1154        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 320, 480, 2)  6           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, Dimension(153 0           conv2d_24[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,840\n",
      "Trainable params: 31,032,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "got unet\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found a sample_weight array with shape (8, 153600, 2). In order to use timestep-wise sample weighting, you should pass a 2D sample_weight array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-cd6e9efa234d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-cd6e9efa234d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m                             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                             callbacks=[model_checkpoint])\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1486\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1486\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             raise ValueError('Found a sample_weight array with shape ' +\n\u001b[0;32m--> 488\u001b[0;31m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                              \u001b[0;34m'In order to use timestep-wise sample weighting, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                              'you should pass a 2D sample_weight array.')\n",
      "\u001b[0;31mValueError\u001b[0m: Found a sample_weight array with shape (8, 153600, 2). In order to use timestep-wise sample weighting, you should pass a 2D sample_weight array."
     ]
    }
   ],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, Reshape\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "class Unet(object):\n",
    "\n",
    "    def __init__(self, train, test, img_rows = 512, img_cols = 512, class_weight = None):\n",
    "        self.training_generator = train\n",
    "        self.validation_generator = test\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.class_weight = class_weight\n",
    "\n",
    "    def load_data(self):\n",
    "        pass\n",
    "\n",
    "    def get_unet(self):\n",
    "\n",
    "        inputs = Input((self.img_rows, self.img_cols, 3))\n",
    "\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        # print(\"conv1 shape:\",conv1.get_shape())\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        # print(\"conv1 shape:\",conv1.get_shape())\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        # print(\"pool1 shape:\",pool1.get_shape())\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        # print(\"conv2 shape:\",conv2.get_shape())\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        # print(\"conv2 shape:\",conv2.get_shape())\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        # print(\"pool2 shape:\",pool2.get_shape())\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        # print(\"conv3 shape:\",conv3.get_shape())\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        # print(\"conv3 shape:\",conv3.get_shape())\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        # print(\"pool3 shape:\",pool3.get_shape())\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        # print(\"conv4 shape:\",conv4.get_shape())\n",
    "        drop4 = Dropout(0.5)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "        # print(\"pool4 shape:\",pool4.get_shape())\n",
    "        # print(\"drop4 shape:\",drop4.get_shape())\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        # print(\"conv5 shape:\",conv5.get_shape())\n",
    "        drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "        # print(\"up6 shape:\",up6.get_shape())\n",
    "        merge6 = concatenate([drop4,up6], axis = 3)\n",
    "        # print(\"merge6 shape:\", merge6.get_shape())\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "        # print(\"conv6 shape:\",conv6.get_shape())\n",
    "        \n",
    "        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        # print(\"up7 shape:\", up7.get_shape())\n",
    "        merge7 = concatenate([conv3,up7], axis = 3)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "        merge8 = concatenate([conv2,up8], axis = 3)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = concatenate([conv1,up9], axis = 3)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(2, 1, activation = 'sigmoid')(conv9)\n",
    "        print(\"output shape: \", conv10.get_shape())\n",
    "        conv10 = Reshape((conv10.get_shape()[1] * conv10.get_shape()[2], 2))(conv10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "        model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy',sample_weight_mode = \"temporal\", metrics = ['accuracy'])\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # print(\"loading data\")\n",
    "        # imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        # print(\"loading data done\")\n",
    "        self.model = self.get_unet()\n",
    "        print(\"got unet\")\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "        print('Fitting model...')\n",
    "        self.model.fit_generator(generator=self.training_generator,\n",
    "                            validation_data=self.validation_generator,\n",
    "                            use_multiprocessing=True,\n",
    "                            workers=6, epochs=1, verbose=1, steps_per_epoch=steps_per_epoch,\n",
    "                            callbacks=[model_checkpoint])\n",
    "        \n",
    "\n",
    "    def save_img(self):\n",
    "\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load('imgs_mask_test.npy')\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"../results/%d.jpg\"%(i))\n",
    "\n",
    "\n",
    "# Sample weights\n",
    "weights = np.zeros((IMG_SIZE[0] * IMG_SIZE[1], 2))\n",
    "weights[:,0] += 0.001\n",
    "weights[:,1] += 1\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (IMG_SIZE[0], IMG_SIZE[1]),\n",
    "          'batch_size': 8,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'sample_weight': weights}\n",
    "\n",
    "\n",
    "steps_per_epoch = int(len(train)//params['batch_size'])\n",
    "training_generator = DataGenerator(train, **params)\n",
    "validation_generator = DataGenerator(test, **params)\n",
    "model = Unet(training_generator, validation_generator, IMG_SIZE[0], IMG_SIZE[1], class_weight=weights)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
